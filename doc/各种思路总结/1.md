### 思路1

disruptor 原理



1. 是一个 ringBuffer，重复利用同一片空间
2. 根据预先设定的消费者数量，生成消费指针
   - writer1,writer2,writer3,writer4
3. 填充时从上次填充下标填充到最小的writer指针（防止被消耗）



如果我们想让我们的id套入disruptor，那我们就必须确定并控制其消费者数量，由于我们在一定时间内会打入大量请求，所以我们需要在这中间修改内容。

如果从一个确定消费者数量模型，转换到不确定消费者数量模型，那我们这里肯定会产生数据竞争。

> 假设你有1024个消费者，然而可能在同一时间内，会打入1w个请求。那这时就会出现1w个请求，根据规则去抢占这1024个消费者，那这里必然产生数据竞争。

既然产生了数据竞争，那肯定少不了同步处理。

同步处理有

- 锁
- cas

cas不适合大量线程执行，仅适合较少线程运行，同时由于go语言特性，其 sync.Mutex 有一个锁升级的过程，所以具体逻辑我们暂时不管。

再根据chan的原理进行评估，本轮优化是否有效

> FIFO，每次发送数据与接收数据，都会上锁



那么我们下来的逻辑

```go
type consume struct{
    mu sync.Mutex
    writeIndex int64
}

type ringBuffer struct{
    buffer []uint64
    
    con []consume
}
```



根据 `atomic.add`方法，为每一个请求申请一个`id`

1. 根据id进行取余（&），分配到不同的格子中
2. 该格子可以理解为消费者，我们对该格子上锁
3. 获取消费id
4. 判断消费ID是否大于生产序列
   - 大于：阻塞等待
   - 小于：直接返回结果




根据上面了逻辑，我们已经成功实现。

但由于goroutine并不是公平调度，会导致部分goroutine消费速度慢于其他goroutine，可能会出现 A goroutine 还在消费第任务1，而B消费者已经消费到任务9999，再由于我们的填充逻辑是根据 `len(buffer) - (producerCursor-minConsumeCursor)` ，导致差值等于`len(buffer)`时，不会出现填充。

解决方法：

- 能够确定每个消费者指针（锁）
  - 如果出现单锁，可能导致性能瓶颈



### 思路2

由于思路一的实现，会导致出现一个中心锁（消费者指针），加上此锁可能就类似chan了，所以本思路，主要用于分布式锁。

大体思路与思路1相等

- 确定消费者数量
- 每个消费者是单线程的（通过锁实现）
- 每个消费者只消费自己的区域，不消费别人的区域。
- 当消费者自己区域消费完毕后，通过chan发信到数据中心，让数据中心拉取相应的任务列表，填充到当前消费者任务列表中
- 同样只有两个指针
  - consumeCursor
  - produceCursor

运行逻辑

1. 获取任务id
2. 分配到不同的消费者
3. 上锁
4. 消费者获取消费指针
5. 判断消费指针是否超出生产指针
   - 超出则等待
   - 没有超出则直接返回数据
6. 解锁



