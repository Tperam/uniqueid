### 唯一ID 来源

本项目是来自于一篇文章所提供的概念

通过mysql的AUTO_INCREMENT实现的ID自增性能较低，会锁全表，同时在分布式Mysql下会出现问题。

通过该文章，我了解到 snowflake算法，后根据学习，发现snowflake算法虽然是完全独立的，但对运维要求较高（时间同步、workid等）。

根据该分布式唯一ID标签，我找到了 美团 Leaf Segment。

#### leaf segment

其原理其实就是通过数据库存储最大ID值，并且每次批量获取ID，减少对数据库的写入。



### 本项目实现思路

本项目实现思路，由于曾经学习过channel，并且根据大佬们的描述，chan的性能是非常低的，所以在此处尝试挑战一下在不使用chan的情况下实现一个生产者消费者模型。

- 生产者：数据库拿取一批ID
- 消费者：每次请求时获取一个ID

#### chan慢的原因

此思路需要从源码写起，后续补充



#### 主体思路

由于chan性能很低（本项目的目标），我们需要尽量避免、减少锁与channel。

计划是学习disruptor的ringbuffer思路，通过消费者指针+生产者指针+ringBuffer





#### 思路1

最开始的思路，非常的狂，尝试不用chan实现

> https://github.com/Tperam/uniqueid/blob/46a7d7808d60d37c6b9a073ca814ddab70594db8/internal/biz/unqiue_ringbuffer.go

```go
type UniqueRingBuffer struct {
	IDBuffer  []uint64 // buffer
	Mask      uint64 // 掩码  buffer[consumer&mask]
	Threshold int64

	// Head ~ Tail 是可用范围
	Head   uint64 // 消费指针
	Tail   uint64 // 生产指针
	lock   *sync.Mutex
	RWLock *sync.RWMutex

	uniqueDao *dao.UniqueDao
	bizTag    string
}
```

```go
func (ub *UniqueRingBuffer) GetID() uint64 {
	re := atomic.AddUint64(&ub.Head, 1)

	if re >= ub.Tail {
		// 尝试抢锁
		ub.lock.Lock()
		// 判断是否还超出
		if re >= ub.Tail {
			// 调用更新函数
			ub.generate(context.TODO())
		}
		ub.lock.Unlock()
	}

	return ub.IDBuffer[re&ub.Mask]
}
```

```go
func (ub *UniqueRingBuffer) Fill(startID uint64, num int) uint64 {
    rangeNum := len(ub.IDBuffer) - int(ub.Tail) - int(ub.Head) // Bug:可能出现 Head > Tail
	if rangeNum > len(ub.IDBuffer) {
		rangeNum = len(ub.IDBuffer)
	}
	if rangeNum > num {
		rangeNum = num
	}

	for i := ub.Tail; i < uint64(rangeNum); i++ {
		ub.IDBuffer[i&ub.Mask] = startID + i
	}

	return startID + uint64(rangeNum)
}

func (ub *UniqueRingBuffer) generate(ctx context.Context) error {
	r, err := ub.uniqueDao.GetSequence(ctx, ub.bizTag)
	if err != nil {
		return err
	}
	ub.Fill(uint64(r.MaxID-int64(r.Step)), int(r.MaxID))
	return nil
}
```

当时的整体思路是，消费者指针通过atomic递增，就不会出现重复的re，既然不会出现重复的re，那我们每次根据`IDBuffer[re&mask]`获取相应的 id，就应该不会重复，并且在生产者大于消费者时，完全没有加锁，速度几乎就是正常读取数组。

虽然思路很好，但是有很多Bug。

我们这里认为每一个goroutine都是有一定顺序去取走数据，例如：

1取走，2取走，3取走，4取走...

但它实际上会出现：

4取走，1取走，3取走，2取走。

这些问题在相同的轮次不会出现任何问题，但当 `tail > len(buffer)`时，会导致出现问题。

有可能出现，Agoroutine拿了消费`ID:1`后，就陷入沉睡，当其他几千几百个goroutine后，A起来拿着`ID 1`去返回。这里就会导致重复。

同时，还有一堆小问题。



#### 思路2

我们及时的发现了思路1的问题，所以做出了相应的改变

```go
func (rb *ringbuffer) GetID() uint64 {
	for {

		head := rb.head
		if head < rb.tail {
			result := rb.buffer[head&rb.mask]
			if atomic.CompareAndSwapUint64(&rb.head, head, head+1) {
				return result
			} else {
				continue
			}
		}
		<-rb.notice

	}
}
```

```go
func (rb *ringbuffer) Fill(startID uint64, num int) (endID uint64) {

	head := rb.head
	tail := rb.tail
	bufferLen := len(rb.buffer)
	fillAmount := uint64(bufferLen) - (tail - head)
	if fillAmount > uint64(num) {
		fillAmount = uint64(num)
	}
	for i := uint64(0); i < fillAmount; i++ {
		rb.buffer[(tail+i)&rb.mask] = startID - uint64(num) + i
		// atomic.AddUint64(&rb.tail, 1)
	}
	atomic.StoreUint64(&rb.tail, rb.tail+fillAmount)
	for rb.head < rb.tail {
		rb.notice <- struct{}{} 
	}
	return startID - uint64(num) + fillAmount
}
```

从最开始的`atomic.AddUint64`改为了cas，当我取到了ID，并且成功占有后，再将值返回，并且将等待阻塞改为了chan。

在生产指针大于消费指针时的逻辑还是没有多少变化，在生产指针跟的上的情况下，效率也是较高的。

同时此处改变了一个填充逻辑，增加了一个唤醒chan

但由于cas是会占用大量的CPU，在goroutine较多时压力CPU压力极大，导致性能极低，表现上甚至不如chan，那这多少让我有点不乐意。



#### 思路3

此版本代码Bug极多... 需要跟思路（也不是像提交名称时所说是disruptor...）

> https://github.com/Tperam/uniqueid/commit/f05286ed6114289cbf29a017f0311b9b57c7a2af

既然上面因为cas枪锁导致了大量占用，那么我们可以设置等待策略，比如每次循环，暂停1ms，或`yield`一下。但这其中其实还是会有一个问题。（有些goroutine可能会出现饿死。）

所以我们采用了其他的解决方案，创建一堆锁，并通过`atomic.AddUint64`分配消费指针，将消费指针以取余（&）的方式分配到不同的锁（轮询算法）。也可以理解为"分布式锁"：将锁拆成多份，每份尽量并行执行。

```go
type consume struct {
	mu        sync.Mutex
	consumed  uint64
	consuming uint64
	sign      chan struct{}
}

type ringBuffer struct {
	buffer       []uint64
	bufferMask   uint64
	consumers    []*consume
	consumerMask uint64

	consumeCursor  uint64
	producerCursor uint64

	waitQueneLock sync.Mutex
	waitQuene     []uint64 // 处理锁

	producerMu sync.Mutex
}
```

```go
func (rb *ringBuffer) GetID() uint64 {
	consumeCursor := atomic.AddUint64(&rb.consumeCursor, 1)

	rb.consumers[consumeCursor&rb.consumerMask].mu.Lock()

	// doslow
	if consumeCursor > rb.producerCursor {

		rb.waitQueneLock.Lock()
		// 如果真的需要等待
		if consumeCursor > rb.producerCursor {
			// 添加到等待队列
			rb.waitQuene = append(rb.waitQuene, consumeCursor&rb.consumerMask)
			rb.consumers[consumeCursor&rb.consumerMask].consuming = consumeCursor
			rb.waitQueneLock.Unlock()
			// 尝试阻塞
			<-rb.consumers[consumeCursor&rb.consumerMask].sign
		} else {
			rb.waitQueneLock.Unlock()
		}

	}
	result := rb.buffer[consumeCursor&rb.bufferMask]
	rb.consumers[consumeCursor&rb.consumerMask].consumed = consumeCursor
	rb.consumers[consumeCursor&rb.consumerMask].mu.Unlock()
	return result
}
```

```go
// 返回长度
func (rb *ringBuffer) Fill(ids []uint64) uint64 {
	rb.producerMu.Lock()
	// 定位消耗指针
	produceCursor := rb.producerCursor
	minConsumed := rb.consumers[0].consumed
	for i := range rb.consumers {
		if rb.consumers[i].consumed < minConsumed {
			minConsumed = rb.consumers[i].consumed
		}
	}

	// 确定可填充数值
    fillable := uint64(len(rb.buffer)) - produceCursor - minConsumed // 这里是bug，正常是(produceCursor-minConsumed)
	if fillable > uint64(len(ids)) {
		fillable = uint64(len(ids))
	}

	// 填充
	for i := uint64(0); i < fillable; i++ {
		rb.buffer[rb.producerCursor&rb.bufferMask] = ids[i]
		atomic.AddUint64(&rb.producerCursor, 1)
	}

	rb.producerMu.Unlock()
	// 解锁
	rb.waitQueneLock.Lock()
	for i := range rb.waitQuene {
		if rb.consumers[rb.waitQuene[i]].consuming < rb.producerCursor {
			rb.consumers[rb.waitQuene[i]].sign <- struct{}{}
		}
	}
	rb.waitQuene = rb.waitQuene[:0]
	rb.waitQueneLock.Unlock()
	return fillable
}
```

咱们的逻辑是这样的

- 每个请求进来后，都让其直接获取请求id。
  - 如果生产者指针大于消费者指针，那么直接返回，虽然有锁，但是由于有多把锁，降低了锁的粒度。
  - 如果超出了生产者指针，则将自己添加到等待队列，并且开启阻塞，等待填充后被唤醒。
- 填充时，根据最低的消费指针决定填充到哪里，避免填充时将上一轮的值覆盖了，导致出现重复值。





虽然有点想法，但是当前版本会出现Bug。该Bug会在如下场景中产生。

- 我们有3个消费需求
- buffer 大小为2
  - 该buffer已被填充
- 有2个消费者

那么，此时将会出现3个goroutine（模拟http请求，每一个消费都会开一个goroutine），每个goroutine都获得到了一个消费指针（1,2,3）

- 第一个goroutine进来，获取到了消费指针1，根据分配，分配到了锁1，但还没抢锁就发生了切换。
- 第二个goroutine进来，正常获取消费指针2，根据分配，分配到了锁2，成功抢锁，并完成执行。
- 第三个goroutine进来，获取到了消费指针3，根据分配，分配到了锁1，成功抢锁，但由于buffer不够，阻塞。

##### bug1 无法填充

当填充时，发现最小消费值为0（生产值为2），导致`buffer-(produceCurosr-minConsumed)`等于0，表可填充值为0，导致无法填充值，出现死锁。

正常需要将填充逻辑中的 consumed 改为 consuming。并且在上锁后的第一步执行，并且在解锁前释放。

##### bug2 细节

就算上面填充逻辑为正常，并且增加逻辑，我们的`consuming`值为3

```go
minConsuming := rb.consumers[0].consuming
for i := range rb.consumers {
    if rb.consumers[i].consuming < minConsumed {
        if rb.consumers[i].consuming == 0 {
            continue
        }
        minConsumed = rb.consumers[i].consuming
    }
}
```

那么，我们将得到结果 `buffer-(produceCurosr-minConsuming)` 2-(2-3) uint64 出现bug

还需要额外判断。

```go
fillable := uint64(len(rb.buffer)) - (produceCursor - minConsuming)
if minConsuming > produceCurosr{
    fillable = rb.buffer
}
if fillable > uint64(len(ids)) {
    fillable = uint64(len(ids))
}
```

##### bug3 重复

上面都是代码实现上的Bug。除了上面的bug，还有逻辑上的Bug。

按照我们上面的逻辑，就会导致`buffer[1&mask]`被浪费。

goroutine3等待填充后，正常消费结束，释放锁。此时goroutine1进入，根据逻辑判断，让其正常执行返回。这里导致重复