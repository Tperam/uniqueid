### 唯一ID 来源

本项目是来自于一篇文章所提供的概念

通过mysql的AUTO_INCREMENT实现的ID自增性能较低，会锁全表，同时在分布式Mysql下会出现问题。

通过该文章，我了解到 snowflake算法，后根据学习，发现snowflake算法虽然是完全独立的，但对运维要求较高（时间同步、workid等）。

根据该分布式唯一ID标签，我找到了 美团 Leaf Segment。

#### leaf segment

其原理其实就是通过数据库存储最大ID值，并且每次批量获取ID，减少对数据库的写入。



### 本项目实现思路

本项目实现思路，由于曾经学习过channel，并且根据大佬们的描述，chan的性能是非常低的，所以在此处尝试挑战一下在不使用chan的情况下实现一个生产者消费者模型。

- 生产者：数据库拿取一批ID
- 消费者：每次请求时获取一个ID

#### chan慢的原因

此思路需要从源码写起，后续补充



#### 主体思路

由于chan性能很低（本项目的目标），我们需要尽量避免、减少锁与channel。

计划是学习disruptor的ringbuffer思路，通过消费者指针+生产者指针+ringBuffer





#### 思路1

最开始的思路，非常的狂，尝试不用chan实现

> https://github.com/Tperam/uniqueid/blob/46a7d7808d60d37c6b9a073ca814ddab70594db8/internal/biz/unqiue_ringbuffer.go

```go
type UniqueRingBuffer struct {
	IDBuffer  []uint64 // buffer
	Mask      uint64 // 掩码  buffer[consumer&mask]
	Threshold int64

	// Head ~ Tail 是可用范围
	Head   uint64 // 消费指针
	Tail   uint64 // 生产指针
	lock   *sync.Mutex
	RWLock *sync.RWMutex

	uniqueDao *dao.UniqueDao
	bizTag    string
}
```

```go
func (ub *UniqueRingBuffer) GetID() uint64 {
	re := atomic.AddUint64(&ub.Head, 1)

	if re >= ub.Tail {
		// 尝试抢锁
		ub.lock.Lock()
		// 判断是否还超出
		if re >= ub.Tail {
			// 调用更新函数
			ub.generate(context.TODO())
		}
		ub.lock.Unlock()
	}

	return ub.IDBuffer[re&ub.Mask]
}
```

```go
func (ub *UniqueRingBuffer) Fill(startID uint64, num int) uint64 {
    rangeNum := len(ub.IDBuffer) - int(ub.Tail) - int(ub.Head) // Bug:可能出现 Head > Tail
	if rangeNum > len(ub.IDBuffer) {
		rangeNum = len(ub.IDBuffer)
	}
	if rangeNum > num {
		rangeNum = num
	}

	for i := ub.Tail; i < uint64(rangeNum); i++ {
		ub.IDBuffer[i&ub.Mask] = startID + i
	}

	return startID + uint64(rangeNum)
}

func (ub *UniqueRingBuffer) generate(ctx context.Context) error {
	r, err := ub.uniqueDao.GetSequence(ctx, ub.bizTag)
	if err != nil {
		return err
	}
	ub.Fill(uint64(r.MaxID-int64(r.Step)), int(r.MaxID))
	return nil
}
```

当时的整体思路是，消费者指针通过atomic递增，就不会出现重复的re，既然不会出现重复的re，那我们每次根据`IDBuffer[re&mask]`获取相应的 id，就应该不会重复，并且在生产者大于消费者时，完全没有加锁，速度几乎就是正常读取数组。

虽然思路很好，但是有很多Bug。

我们这里认为每一个goroutine都是有一定顺序去取走数据，例如：

1取走，2取走，3取走，4取走...

但它实际上会出现：

4取走，1取走，3取走，2取走。

这些问题在相同的轮次不会出现任何问题，但当 `tail > len(buffer)`时，会导致出现问题。

有可能出现，Agoroutine拿了消费`ID:1`后，就陷入沉睡，当其他几千几百个goroutine后，A起来拿着`ID 1`去返回。这里就会导致重复。

同时，还有一堆小问题。



#### 思路2

我们及时的发现了思路1的问题，所以做出了相应的改变

```go
func (rb *ringbuffer) GetID() uint64 {
	for {

		head := rb.head
		if head < rb.tail {
			result := rb.buffer[head&rb.mask]
			if atomic.CompareAndSwapUint64(&rb.head, head, head+1) {
				return result
			} else {
				continue
			}
		}
		<-rb.notice

	}
}
```

```go
func (rb *ringbuffer) Fill(startID uint64, num int) (endID uint64) {

	head := rb.head
	tail := rb.tail
	bufferLen := len(rb.buffer)
	fillAmount := uint64(bufferLen) - (tail - head)
	if fillAmount > uint64(num) {
		fillAmount = uint64(num)
	}
	for i := uint64(0); i < fillAmount; i++ {
		rb.buffer[(tail+i)&rb.mask] = startID - uint64(num) + i
		// atomic.AddUint64(&rb.tail, 1)
	}
	atomic.StoreUint64(&rb.tail, rb.tail+fillAmount)
	for rb.head < rb.tail {
		rb.notice <- struct{}{} 
	}
	return startID - uint64(num) + fillAmount
}
```

从最开始的`atomic.AddUint64`改为了cas，当我取到了ID，并且成功占有后，再将值返回，并且将等待阻塞改为了chan。

在生产指针大于消费指针时的逻辑还是没有多少变化，在生产指针跟的上的情况下，效率也是较高的。

同时此处改变了一个填充逻辑，增加了一个唤醒chan

但由于cas是会占用大量的CPU，在goroutine较多时压力CPU压力极大，导致性能极低，表现上甚至不如chan，那这多少让我有点不乐意。



#### 思路3



